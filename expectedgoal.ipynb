{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e34aede-fd36-40b4-af3d-cd5aed6eb3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Obtaining dependency information for catboost from https://files.pythonhosted.org/packages/1c/e1/78e635a1e5f0066bd02a1ecfd658ad09fe30d275c65c2d0dd76fe253e648/catboost-1.2.7-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached catboost-1.2.7-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: graphviz in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (6.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (3.1.4)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\91798\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly->catboost) (1.29.1)\n",
      "Using cached catboost-1.2.7-cp311-cp311-win_amd64.whl (101.7 MB)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-1.2.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc68504-bf6c-4fec-af31-e30056a5f7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91798\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost MAE: 0.23\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 633\n",
      "[LightGBM] [Info] Number of data points in the train set: 1111, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 1.317462\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM MAE: 0.24\n",
      "SVR MAE: 0.41\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Neural Network MAE: 0.25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Ensemble Predicted xG for Team 12 vs Team 4 at Venue 0: 0.41\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\91798\\Desktop\\html\\jypter\\Football-main\\Football-main\\matches.csv\")\n",
    "\n",
    "# Select relevant columns\n",
    "df = df[['team', 'opponent', 'venue', 'xg', 'sh', 'sot', 'dist', 'fk', 'pk', 'pkatt']]\n",
    "\n",
    "# Convert categorical values to numeric using Label Encoding\n",
    "label_encoders = {}\n",
    "for col in ['team', 'opponent']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Manually map venue to 0 (Home) and 1 (Away)\n",
    "venue_mapping = {'Home': 0, 'Away': 1}\n",
    "df['venue'] = df['venue'].map(venue_mapping)\n",
    "\n",
    "# Feature Engineering: Calculate accuracy and efficiency metrics\n",
    "df['shot_accuracy'] = df['sot'] / df['sh'].replace(0, np.nan)  # Shots on target / Total shots\n",
    "df['penalty_conversion'] = df['pk'] / df['pkatt'].replace(0, np.nan)  # Penalties scored / Penalties attempted\n",
    "df.fillna(0, inplace=True)  # Replace NaN values with 0\n",
    "\n",
    "# Feature Engineering: Rolling averages for last 5 games\n",
    "df['team_xg_5g'] = df.groupby('team')['xg'].transform(lambda x: x.rolling(5, min_periods=1).mean())\n",
    "df['opponent_xg_5g'] = df.groupby('opponent')['xg'].transform(lambda x: x.rolling(5, min_periods=1).mean())\n",
    "\n",
    "# Feature Engineering: Head-to-head xG averages\n",
    "df['h2h_xg'] = df.groupby(['team', 'opponent'])['xg'].transform(lambda x: x.expanding().mean())\n",
    "\n",
    "# Define features and target\n",
    "X = df[['team', 'opponent', 'venue', 'sh', 'sot', 'dist', 'fk', 'pk', 'pkatt', 'shot_accuracy', 'penalty_conversion', 'team_xg_5g', 'opponent_xg_5g', 'h2h_xg']]\n",
    "y = df['xg']  # Predicting Expected Goals (xG)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train different ML models\n",
    "models = {\n",
    "    'CatBoost': CatBoostRegressor(iterations=500, depth=8, learning_rate=0.05, verbose=0),\n",
    "    'LightGBM': LGBMRegressor(n_estimators=300, learning_rate=0.03, max_depth=12),\n",
    "    'SVR': SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "}\n",
    "\n",
    "# Train Neural Network Model\n",
    "nn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='mae')\n",
    "nn_model.fit(X_train, y_train, epochs=100, batch_size=8, verbose=0)\n",
    "\n",
    "# Evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    error = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"{name} MAE: {error:.2f}\")\n",
    "\n",
    "# Predict with Neural Network\n",
    "nn_pred = nn_model.predict(X_test).flatten()\n",
    "nn_error = mean_absolute_error(y_test, nn_pred)\n",
    "print(f\"Neural Network MAE: {nn_error:.2f}\")\n",
    "\n",
    "# Function to predict xG using Ensemble Model\n",
    "def predict_xg(team, opponent, venue):\n",
    "    input_data = pd.DataFrame([[team, opponent, venue, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], columns=['team', 'opponent', 'venue', 'sh', 'sot', 'dist', 'fk', 'pk', 'pkatt', 'shot_accuracy', 'penalty_conversion', 'team_xg_5g', 'opponent_xg_5g', 'h2h_xg'])\n",
    "    catboost_pred = models['CatBoost'].predict(input_data)[0]\n",
    "    lgbm_pred = models['LightGBM'].predict(input_data)[0]\n",
    "    svr_pred = models['SVR'].predict(input_data)[0]\n",
    "    nn_pred = nn_model.predict(input_data)[0][0]\n",
    "    \n",
    "    # Weighted averaging for better accuracy\n",
    "    ensemble_pred = (0.3 * catboost_pred + 0.3 * lgbm_pred + 0.2 * svr_pred + 0.2 * nn_pred)\n",
    "    print(f\"Ensemble Predicted xG for Team {team} vs Team {opponent} at Venue {venue}: {ensemble_pred:.2f}\")\n",
    "    \n",
    "# Example usage\n",
    "predict_xg(12, 4, 0)  # Example: Team 12 vs Team 4 at Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5bbf23a-8807-48d9-b14e-30d0f648fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for col in ['team', 'opponent']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30906161-ea2d-4206-918f-cccaaca91bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     team  opponent  venue   xg\n",
      "27     12        13      0  2.6\n",
      "656    12        13      0  1.5\n"
     ]
    }
   ],
   "source": [
    "team_name = 12\n",
    "opponent_name = 13\n",
    "\n",
    "# Convert team names to encoded values\n",
    "team_encoded = label_encoders['team'].transform([team_name])[0]\n",
    "opponent_encoded = label_encoders['team'].transform([opponent_name])[0]\n",
    "\n",
    "# Find past xG values\n",
    "h2h_xg_matches = df[(df['team'] == team_encoded) & (df['opponent'] == opponent_encoded) & (df['venue'] == 0)]\n",
    "print(h2h_xg_matches[['team', 'opponent', 'venue', 'xg']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6143f998-88e9-4e4c-b7c6-20954b96151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91798\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost MAE: 0.55\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 48\n",
      "[LightGBM] [Info] Number of data points in the train set: 1111, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 1.317462\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM MAE: 0.55\n",
      "SVR MAE: 0.60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Neural Network MAE: 0.59\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Ensemble Predicted xG for Team 12 vs Team 4 at Venue 1: 2.04\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\91798\\Desktop\\html\\jypter\\Football-main\\Football-main\\matches.csv\")\n",
    "\n",
    "# Select relevant columns\n",
    "df = df[['team', 'opponent', 'venue', 'xg']]\n",
    "\n",
    "# Convert categorical values to numeric using Label Encoding\n",
    "label_encoders = {}\n",
    "for col in ['team', 'opponent']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Manually map venue to 0 (Home) and 1 (Away)\n",
    "venue_mapping = {'Home': 0, 'Away': 1}\n",
    "df['venue'] = df['venue'].map(venue_mapping)\n",
    "\n",
    "# Define features and target\n",
    "X = df[['team', 'opponent', 'venue']]\n",
    "y = df['xg']  # Predicting Expected Goals (xG)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train different ML models\n",
    "models = {\n",
    "    'CatBoost': CatBoostRegressor(iterations=500, depth=8, learning_rate=0.05, verbose=0),\n",
    "    'LightGBM': LGBMRegressor(n_estimators=300, learning_rate=0.03, max_depth=12),\n",
    "    'SVR': SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "}\n",
    "\n",
    "# Train Neural Network Model\n",
    "nn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='mae')\n",
    "nn_model.fit(X_train, y_train, epochs=100, batch_size=8, verbose=0)\n",
    "\n",
    "# Evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    error = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"{name} MAE: {error:.2f}\")\n",
    "\n",
    "# Predict with Neural Network\n",
    "nn_pred = nn_model.predict(X_test).flatten()\n",
    "nn_error = mean_absolute_error(y_test, nn_pred)\n",
    "print(f\"Neural Network MAE: {nn_error:.2f}\")\n",
    "\n",
    "# Function to predict xG using Ensemble Model\n",
    "def predict_xg(team, opponent, venue):\n",
    "    input_data = pd.DataFrame([[team, opponent, venue]], columns=['team', 'opponent', 'venue'])\n",
    "    catboost_pred = models['CatBoost'].predict(input_data)[0]\n",
    "    lgbm_pred = models['LightGBM'].predict(input_data)[0]\n",
    "    svr_pred = models['SVR'].predict(input_data)[0]\n",
    "    nn_pred = nn_model.predict(input_data)[0][0]\n",
    "    \n",
    "    # Weighted averaging for better accuracy\n",
    "    ensemble_pred = (0.3 * catboost_pred + 0.3 * lgbm_pred + 0.2 * svr_pred + 0.2 * nn_pred)\n",
    "    print(f\"Ensemble Predicted xG for Team {team} vs Team {opponent} at Venue {venue}: {ensemble_pred:.2f}\")\n",
    "    \n",
    "# Example usage\n",
    "predict_xg(12, 4, 1)  # Example: Team 12 vs Team 4 at Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fbb703e-38cf-40a0-bfec-34fdfb45898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Ensemble Predicted xG for Team 12 vs Team 13 at Venue 1: 1.85\n"
     ]
    }
   ],
   "source": [
    "predict_xg(12, 13, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40222065-7ea1-4ec2-af64-4a5e498140d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Ensemble Predicted xG for Team 12 vs Team 13 at Venue 0: 1.76\n"
     ]
    }
   ],
   "source": [
    "predict_xg(12, 13, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6746fe9-ed7b-48eb-b4cd-8864cda298cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
